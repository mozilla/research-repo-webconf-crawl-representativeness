# The representativeness of automated Web crawls as a surrogate for human browsing - companion repository

This repository contains or links to all assets relevant to the WWW'20 paper: The representative of automated Web crawls as a surrogate for human browsing.

* Lists used for crawls - under lists directory
* Trexa repo - https://github.com/mozilla/trexa
* Crawl preparation - pre crawl and depth crawl code - https://github.com/mozilla/crawl-prep
* Crawl database - [Google Doc](https://docs.google.com/spreadsheets/d/1HlocB39Ujaw2JH4Nm_0lXFqQ6GcQjJ7ONHHLFq-NReI/)
* Crawl downloads - coming (est Apr, 2019)
* Alternate orchestration repo - https://github.com/birdsarah/faust-selenium
