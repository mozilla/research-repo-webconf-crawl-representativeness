# The representativeness of automated Web crawls as a surrogate for human browsing - companion repository

This repository contains or links to all assets relevant to the WWW'20 paper: The representative of automated Web crawls as a surrogate for human browsing.

* Lists used for crawls - under lists directory
* Trexa repo - https://github.com/mozilla/trexa
* Crawl preparation - pre crawl and depth crawl code - https://github.com/mozilla/crawl-prep
* Crawl database - [Google Doc](https://docs.google.com/spreadsheets/d/1HlocB39Ujaw2JH4Nm_0lXFqQ6GcQjJ7ONHHLFq-NReI/)
* Crawl downloads - coming (est Apr 2020)
* Alternate orchestration repo - https://github.com/birdsarah/faust-selenium
* [List comparison analysis](./list-comparison/top-site-list-comparison.ipynb)
* DP-protected top-level domain visit counts for opt-in human users (est Apr 30, 2020)
